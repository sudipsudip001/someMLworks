{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# let's start the process to find the linear regression for multiple variables\n",
        "# first we'll import the libraries required\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "hh5Dwoah14S7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# next step is simply to define the variables that we'll be using\n",
        "# for multiple regression we'll have multiple features for which we'll be using vectors\n",
        "x = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1,  35]])\n",
        "y = np.array([460, 232, 178])"
      ],
      "metadata": {
        "id": "HaMpGSGD2SFf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following arrays/vectors are declared from the table:\n",
        "\n",
        "| Size (sqft) | Number of Bedrooms  | Number of floors | Age of  Home | Price (1000s dollars)  |   \n",
        "| ----------------| ------------------- |----------------- |--------------|-------------- |  \n",
        "| 2104            | 5                   | 1                | 45           | 460           |  \n",
        "| 1416            | 3                   | 2                | 40           | 232           |  \n",
        "| 852             | 2                   | 1                | 35           | 178           |  "
      ],
      "metadata": {
        "id": "RvOwUg143HrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The equation for a multiple linear regression is given as:\n",
        "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b $$\n",
        "$$ where, w_0, w_1, w_2...w_{n-1}$$ and b are the parameters such that w is an n-dimensional vector and b is a scalar."
      ],
      "metadata": {
        "id": "ZK8W2dpn4a98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for the initial purpose let us randomly define the values of w and b\n",
        "w = np.array([20, 30, 40, 50])\n",
        "b = 60"
      ],
      "metadata": {
        "id": "vp6MPwmN5p6D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first we'll be preparing the prediction function that'll be used to predict the price of house\n",
        "def predict(x, w, b):\n",
        "  p = np.dot(w, x) + b\n",
        "  return p\n",
        "\n",
        "# let us check what the predicted price would be for the first data from the table i.e. [2104, 5, 1, 45]\n",
        "x_init = x[0,:]\n",
        "got = predict(x_init,w,b)\n",
        "print('The value of house according to the selected parameters(w,b) and values(x) is: ', got)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntw9Eygg6-M5",
        "outputId": "25c9826d-a45a-407f-fdef-7570a84b76cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of house according to the selected parameters(w,b) and values(x) is:  44580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's way beyond the actual value. So, we have to have more accurate values of w and b. We'll be getting that from the gradient descent but first let's calculate the value of cost function for all the values given in x."
      ],
      "metadata": {
        "id": "3H4IJXYC8Xgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(x, y, w, b):\n",
        "  m = x.shape[0]\n",
        "  cost = 0\n",
        "  for i in range(m):\n",
        "    p = np.dot(x[i], w) + b\n",
        "    cost += p\n",
        "  cost /= (2*m)\n",
        "  return cost"
      ],
      "metadata": {
        "id": "iir10YIs8qKz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's find what the cost would be if we use the same old values of parameters w and b\n",
        "got = cost(x, y, w, b)\n",
        "print(\"The total cost is: \", got)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhlpyflx9wN1",
        "outputId": "680dbd3c-351c-4476-c9b9-53e8561405b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total cost is:  15680.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cost is way too much so hope we'd be able to improve it by finding the most suitable parameter values.\n",
        "The first step to finding the correct values for w and b is given by the gradient descent for which the formula is given by:\n",
        "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
        "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  \\; & \\text{for j = 0..n-1}\\newline\n",
        "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
        "\\end{align*}$$\n"
      ],
      "metadata": {
        "id": "wl-846UOMUt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that we have to calculate the value of gradients for this process for which the formulas are:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)}  \\\\\n",
        "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})\n",
        "\\end{align}\n",
        "$$"
      ],
      "metadata": {
        "id": "F-Veb6fhMyE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's calculate the gradient\n",
        "def gradient(x, y, w, b):\n",
        "  m, n = x.shape\n",
        "  dj_db = 0.\n",
        "  dj_dw = np.zeros((n,))\n",
        "  for i in range(m):\n",
        "    err = (np.dot(w,x[i]) + b) - y[i]\n",
        "    for j in range(n):\n",
        "      dj_dw[j] += err*x[i][j]\n",
        "    dj_db += err\n",
        "  dj_db /= m\n",
        "  dj_dw /= m\n",
        "  return dj_db, dj_dw\n",
        "\n",
        "# now it's time to calculate the gradient descent function\n",
        "def gradient_descent(x, y, w, b, gradient, iterations, alpha):\n",
        "  for i in range(iterations):\n",
        "    dj_db, dj_dw = gradient(x, y, w, b)\n",
        "    w -= alpha*dj_dw\n",
        "    b -= alpha*dj_db\n",
        "  return b, w\n",
        "\n",
        "# since the gradient descent function has been completed now let's create some values of w and b and pass them to the gradient descent function\n",
        "m, n = x.shape\n",
        "w_init = np.zeros(n,)\n",
        "b_init = 0.\n",
        "alpha = 5.0e-7\n",
        "iterations = 1000\n",
        "b, w = gradient_descent(x, y, w_init, b_init, gradient, iterations, alpha)\n",
        "print(\"The return value of parameters from the function for b and w are: b = \", b, \" w = \", w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmLxdMqxM-nP",
        "outputId": "749d8b20-ab1f-44da-eda2-31c608c88209"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The return value of parameters from the function for b and w are: b =  -0.002235407530932535  w =  [ 0.20396569  0.00374919 -0.0112487  -0.0658614 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check how accurate these parameters define our examples.\n",
        "x_init = x[0,:]\n",
        "got = predict(x_init,w,b)\n",
        "print('The value of house according to the selected parameters(w,b) and values(x) is: ', got)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfoyYCDsT6Z1",
        "outputId": "0aee361d-8834-4732-95da-16b1e7ddd9b4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of house according to the selected parameters(w,b) and values(x) is:  426.18530497189204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# That's pretty close to the actual value i.e. 460. Now let's find the total cost of the model\n",
        "got = cost(x, y, w, b)\n",
        "print(\"The total cost is: \", got)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLNWFlxBUIU9",
        "outputId": "e2485f3b-333b-4df4-d476-ad9e58df063f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total cost is:  147.3034013085119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since 147.3034 is pretty small in comparison to 15680, we can consider this experiment as a success! And this is thus the procedure to find the linear regression for multiple variables."
      ],
      "metadata": {
        "id": "7oqR-mr4Uiiq"
      }
    }
  ]
}